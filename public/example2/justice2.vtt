WEBVTT

00:18.000 --> 00:23.000
www.AprilSeason.com

00:24.000 --> 00:28.000
Putting a price tag on life

00:29.990 --> 00:34.860
Last time, we argued about

00:34.960 --> 00:37.760
the case of The Queen v. Dudley & Stephens,

00:39.600 --> 00:42.870
the lifeboat case, the case of cannibalism at sea.

00:44.040 --> 00:49.820
And with the arguments about the lifeboat in mind,

00:50.000 --> 00:53.060
the arguments for and against what Dudley and Stephens did in mind,

00:53.339 --> 01:00.159
let's turn back to the philosophy, the utilitarian philosophy of Jeremy Bentham.

01:02.120 --> 01:06.780
Bentham was born in England in 1748. At the age of 12, he went to Oxford.

01:07.399 --> 01:11.699
At 15, he went to law school. He was admitted to the Bar at age 19

01:11.920 --> 01:14.100
but he never practiced law.

01:14.800 --> 01:19.820
Instead, he devoted his life to jurisprudence and moral philosophy.

01:21.800 --> 01:26.500
Last time, we began to consider Bentham's version of utilitarianism.

01:27.880 --> 01:30.860
The main idea is simply stated and it's this:

01:33.039 --> 01:37.539
The highest principle of morality, whether personal or political morality,

01:39.000 --> 01:45.300
is to maximize the general welfare, or the collective happiness,

01:46.679 --> 01:48.659
or the overall balance of pleasure over pain;

01:50.160 --> 01:53.540
in a phrase, maximize utility.

01:56.280 --> 01:59.540
Bentham arrives at this principle by the following line of reasoning:

02:00.919 --> 02:02.419
We're all governed by pain and pleasure,

02:03.280 --> 02:06.380
they are our sovereign masters, and so any moral system

02:06.600 --> 02:07.900
has to take account of them.

02:09.120 --> 02:11.860
How best to take account? By maximizing.

02:13.920 --> 02:17.980
And this leads to the principle of the greatest good for the greatest number.

02:19.359 --> 02:21.609
What exactly should we maximize?

02:23.000 --> 02:27.620
Bentham tells us happiness, or more precisely, utility -

02:29.079 --> 02:32.019
maximizing utility as a principle not only for individuals

02:32.440 --> 02:34.900
but also for communities and for legislators.

02:36.680 --> 02:39.350
"What, after all, is a community?" Bentham asks.

02:41.359 --> 02:44.139
It's the sum of the individuals who comprise it.

02:45.429 --> 02:47.779
And that's why in deciding the best policy,

02:48.160 --> 02:51.940
in deciding what the law should be, in deciding what's just,

02:52.920 --> 02:56.420
citizens and legislators should ask themselves the question

02:57.010 --> 03:00.670
if we add up all of the benefits of this policy

03:03.959 --> 03:09.699
and subtract all of the costs, the right thing to do

03:10.760 --> 03:16.500
is the one that maximizes the balance of happiness over suffering.

03:20.959 --> 03:22.619
That's what it means to maximize utility.

03:22.959 --> 03:29.619
Now, today, I want to see whether you agree or disagree with it,

03:31.160 --> 03:33.460
and it often goes, this utilitarian logic,

03:33.799 --> 03:36.059
under the name of cost-benefit analysis,

03:36.840 --> 03:42.380
which is used by companies and by governments all the time.

03:43.880 --> 03:46.340
And what it involves is placing a value,

03:46.760 --> 03:51.300
usually a dollar value, to stand for utility on the costs

03:51.480 --> 03:54.700
and the benefits of various proposals.

03:56.359 --> 03:59.659
Recently, in the Czech Republic, there was a proposal

03:59.839 --> 04:05.739
to increase the excise tax on smoking. Philip Morris, the tobacco company,

04:07.119 --> 04:10.659
does huge business in the Czech Republic.

04:11.000 --> 04:14.140
They commissioned a study, a cost-benefit analysis

04:15.519 --> 04:19.819
of smoking in the Czech Republic, and what their cost-benefit

04:20.039 --> 04:28.779
analysis found was the government gains by having Czech citizens smoke.

04:29.800 --> 04:32.020
Now, how do they gain?

04:32.640 --> 04:37.060
It's true that there are negative effects to the public finance

04:37.440 --> 04:41.420
of the Czech government because there are increased health care

04:41.680 --> 04:45.180
costs for people who develop smoking-related diseases.

04:47.280 --> 04:49.460
On the other hand, there were positive effects

04:50.520 --> 04:54.340
and those were added up on the other side of the ledger.

04:55.520 --> 04:57.580
The positive effects included, for the most part,

04:57.800 --> 05:02.580
various tax revenues that the government derives from the sale

05:02.800 --> 05:04.940
of cigarette products, but it also included

05:05.159 --> 05:08.069
health care savings to the government when people die early,

05:09.200 --> 05:12.740
pension savings -- you don't have to pay pensions for as long -

05:13.479 --> 05:16.579
and also, savings in housing costs for the elderly.

05:19.080 --> 05:22.020
And when all of the costs and benefits were added up,

05:23.800 --> 05:29.860
the Philip Morris study found that there is a net public finance gain

05:30.880 --> 05:35.220
in the Czech Republic of $147,000,000,

05:36.609 --> 05:40.419
and given the savings in housing, in health care, and pension costs,

05:41.680 --> 05:47.660
the government enjoys savings of over $1,200 for each person

05:48.000 --> 05:50.900
who dies prematurely due to smoking.

05:52.200 --> 05:53.580
Cost-benefit analysis.

05:54.560 --> 05:59.180
Now, those among you who are defenders of utilitarianism

05:59.520 --> 06:02.180
may think that this is an unfair test.

06:03.440 --> 06:05.460
Philip Morris was pilloried in the press

06:05.800 --> 06:09.100
and they issued an apology for this heartless calculation.

06:11.250 --> 06:14.980
You may say that what's missing here is something that the utilitarian

06:15.200 --> 06:20.500
can easily incorporate, namely the value to the person

06:21.039 --> 06:23.819
and to the families of those who die from lung cancer.

06:25.719 --> 06:28.899
What about the value of life?

06:29.240 --> 06:35.500
Some cost-benefit analyses incorporate a measure for the value of life.

06:36.880 --> 06:40.540
One of the most famous of these involved the Ford Pinto case.

06:41.120 --> 06:42.900
Did any of you read about that?

06:43.440 --> 06:44.580
This was back in the 1970s.

06:44.760 --> 06:46.180
Do you remember what the Ford Pinto was,

06:46.359 --> 06:48.299
a kind of car? Anybody?

06:51.159 --> 06:54.459
It was a small car, subcompact car, very popular,

06:55.680 --> 06:59.340
but it had one problem, which is the fuel tank

06:59.560 --> 07:02.860
was at the back of the car and in rear collisions,

07:03.039 --> 07:08.859
the fuel tank exploded and some people were killed

07:09.239 --> 07:11.819
and some severely injured.

07:14.039 --> 07:17.419
Victims of these injuries took Ford to court to sue.

07:18.919 --> 07:22.059
And in the court case, it turned out that Ford

07:22.239 --> 07:26.579
had long since known about the vulnerable fuel tank

07:27.440 --> 07:31.340
and had done a cost-benefit analysis to determine whether it would be

07:31.560 --> 07:36.620
worth it to put in a special shield that would

07:36.840 --> 07:39.020
protect the fuel tank and prevent it from exploding.

07:40.640 --> 07:42.140
They did a cost-benefit analysis.

07:42.479 --> 07:48.779
The cost per part to increase the safety of the Pinto,

07:50.560 --> 07:52.780
they calculated at $11.00 per part.

07:55.880 --> 08:00.940
And here's -- this was the cost-benefit analysis that emerged in the trial.

08:03.120 --> 08:08.580
Eleven dollars per part at 12.5 million cars and trucks

08:10.109 --> 08:16.019
came to a total cost of $137 million to improve the safety.

08:17.400 --> 08:21.340
But then they calculated the benefits of spending all this money

08:21.560 --> 08:25.140
on a safer car and they counted 180 deaths

08:27.090 --> 08:30.990
and they assigned a dollar value, $200,000 per death,

08:32.470 --> 08:38.980
180 injuries, $67,000, and then the costs to repair,

08:39.319 --> 08:41.099
the replacement cost for 2,000 vehicles,

08:41.520 --> 08:46.970
it would be destroyed without the safety device $700 per vehicle.

08:48.360 --> 08:53.180
So the benefits turned out to be only $49.5 million

08:53.720 --> 08:57.000
and so they didn't install the device.

08:58.040 --> 09:01.920
Needless to say, when this memo of the

09:02.000 --> 09:06.020
Ford Motor Company's cost-benefit analysis came out in the trial,

09:09.240 --> 09:13.020
it appalled the jurors, who awarded a huge settlement.

09:16.079 --> 09:19.379
Is this a counterexample to the utilitarian idea of calculating?

09:20.610 --> 09:24.340
Because Ford included a measure of the value of life.

09:25.160 --> 09:31.100
Now, who here wants to defend cost-benefit analysis

09:32.060 --> 09:35.380
from this apparent counterexample?

09:35.640 --> 09:36.980
Who has a defense?

09:38.640 --> 09:41.900
Or do you think this completely destroys the whole

09:42.079 --> 09:45.819
utilitarian calculus? Yes?

09:47.520 --> 09:50.020
Well, I think that once again, they've made the same mistake

09:50.120 --> 09:52.640
the previous case did, that they assigned a dollar value

09:52.740 --> 09:54.340
to human life, and once again,

09:54.600 --> 09:56.580
they failed to take account things like suffering

09:56.880 --> 09:58.220
and emotional losses by the families.

09:58.760 --> 10:01.700
I mean, families lost earnings but they also lost a loved one

10:01.880 --> 10:05.650
and that is more valued than $200,000.

10:06.480 --> 10:08.620
Right and -- wait, wait, wait, that's good. What's your name?

10:08.959 --> 10:10.299
Julie Roteau .

10:10.400 --> 10:15.060
So if $200,000, Julie, is too low a figure

10:15.400 --> 10:17.620
because it doesn't include the loss of a loved one

10:19.050 --> 10:22.140
and the loss of those years of life, what would be -

10:22.630 --> 10:25.420
what do you think would be a more accurate number?

10:27.410 --> 10:29.660
I don't believe I could give a number. I think that this sort of analysis

10:29.880 --> 10:32.420
shouldn't be applied to issues of human life.

10:32.959 --> 10:34.499
I think it can't be used monetarily.

10:35.360 --> 10:39.660
So they didn't just put too low a number, Julie says.

10:40.000 --> 10:41.980
They were wrong to try to put any number at all.

10:44.680 --> 10:46.380
All right, let's hear someone who -

10:47.280 --> 10:48.940
You have to adjust for inflation.

10:49.870 --> 10:51.740
You have to adjust for inflation.

10:57.920 --> 10:59.520
All right, fair enough.

11:00.380 --> 11:01.900
So what would the number be now?

11:03.010 --> 11:05.050
This was 35 years ago.

11:06.329 --> 11:07.479
Two million dollars.

11:07.800 --> 11:11.660
Two million dollars? You would put two million?

11:12.280 --> 11:12.940
And what's your name?

11:13.199 --> 11:14.019
Voytek

11:14.120 --> 11:16.740
Voytek says we have to allow for inflation.

11:17.439 --> 11:18.739
We should be more generous.

11:19.719 --> 11:21.659
Then would you be satisfied that this is the right way of

11:21.880 --> 11:23.420
thinking about the question?

11:24.160 --> 11:27.980
I guess, unfortunately, it is for -

11:29.600 --> 11:33.290
there needs to be a number put somewhere, like, I'm not sure

11:33.480 --> 11:35.380
what that number would be, but I do agree that

11:35.640 --> 11:40.500
there could possibly be a number put on the human life.

11:41.150 --> 11:46.260
All right, so Voytek says, and here, he disagrees with Julie.

11:46.839 --> 11:48.939
Julie says we can't put a number on human life

11:49.930 --> 11:51.500
for the purpose of a cost-benefit analysis.

11:51.839 --> 11:55.619
Voytek says we have to because we have to make decisions somehow.

12:00.089 --> 12:01.739
What do other people think about this?

12:02.079 --> 12:04.499
Is there anyone prepared to defend cost-benefit analysis

12:05.120 --> 12:09.820
here as accurate as desirable? Yes? Go ahead.

12:10.480 --> 12:12.300
I think that if Ford and other car companies

12:12.520 --> 12:16.220
didn't use cost-benefit analysis, they'd eventually go out of business

12:16.560 --> 12:19.840
because they wouldn't be able to be profitable and millions of people

12:19.939 --> 12:21.379
wouldn't be able to use their cars to get to jobs,

12:21.640 --> 12:23.780
to put food on the table, to feed their children.

12:24.670 --> 12:27.380
So I think that if cost-benefit analysis isn't employed,

12:27.719 --> 12:32.339
the greater good is sacrificed, in this case.

12:32.959 --> 12:34.059
All right, let me add. What's your name?

12:34.319 --> 12:35.259
Raul.

12:35.360 --> 12:40.580
Raul, there was recently a study done about cell phone use by a driver

12:40.760 --> 12:43.460
when people are driving a car, and there was a debate

12:43.849 --> 12:44.819
whether that should be banned.

12:45.040 --> 12:46.120
Yeah.

12:46.640 --> 12:55.300
And the figure was that some 2,000 people die as a result

12:55.480 --> 12:59.780
of accidents each year using cell phones.

13:01.219 --> 13:04.419
And yet, the cost-benefit analysis which was done by the

13:04.640 --> 13:08.300
Center for Risk Analysis at Harvard found that

13:08.520 --> 13:11.460
if you look at the benefits of the cell phone use

13:11.880 --> 13:17.840
and you put some value on the life, it comes out about the same

13:19.199 --> 13:22.259
because of the enormous economic benefit of enabling people

13:22.480 --> 13:25.300
to take advantage of their time, not waste time, be able to make deals

13:25.599 --> 13:27.899
and talk to friends and so on while they're driving.

13:30.319 --> 13:33.139
Doesn't that suggest that it's a mistake to try to put

13:33.360 --> 13:36.140
monetary figures on questions of human life?

13:37.870 --> 13:42.030
Well, I think that if the great majority of people try to

13:42.130 --> 13:44.410
derive maximum utility out of a service,

13:44.500 --> 13:47.380
like using cell phones and the convenience that cell phones provide,

13:47.760 --> 13:52.760
that sacrifice is necessary for satisfaction to occur.

13:53.280 --> 13:55.040
You're an outright utilitarian.

13:55.199 --> 13:57.739
Yes. Okay.

13:59.439 --> 14:01.219
All right then, one last question, Raul. - Okay.

14:03.120 --> 14:07.140
And I put this to Voytek, what dollar figure should

14:07.319 --> 14:10.699
be put on human life to decide whether to ban the use of cell phones?

14:13.110 --> 14:16.670
Well, I don't want to arbitrarily calculate a figure,

14:16.760 --> 14:18.800
I mean, right now. I think that -

14:21.439 --> 14:23.039
You want to take it under advisement?

14:23.719 --> 14:25.019
Yeah, I'll take it under advisement.

14:25.120 --> 14:28.020
But what, roughly speaking, would it be? You got 2,300 deaths. - Okay.

14:29.040 --> 14:30.930
You got to assign a dollar value to know whether you want

14:31.030 --> 14:34.700
to prevent those deaths by banning the use of cell phones in cars. - Okay.

14:35.390 --> 14:40.490
So what would your hunch be? How much? A million?

14:41.010 --> 14:44.230
Two million? Two million was Voytek's figure. - Yeah.

14:44.319 --> 14:46.129
Is that about right? - Maybe a million.

14:46.310 --> 14:47.280
A million? - Yeah.

14:47.510 --> 14:52.710
You know, that's good. Thank you. -Okay.

14:54.589 --> 14:57.909
So, these are some of the controversies that arise these days

14:58.010 --> 15:02.270
from cost-benefit analysis, especially those that involve placing a

15:02.370 --> 15:04.960
dollar value on everything to be added up.

15:06.719 --> 15:09.749
Well, now I want to turn to your objections,

15:10.050 --> 15:14.210
to your objections not necessarily to cost-benefit analysis specifically,

15:14.839 --> 15:20.139
because that's just one version of the utilitarian logic in practice today,

15:21.939 --> 15:27.779
but to the theory as a whole, to the idea that the right thing to do,

15:30.300 --> 15:35.540
the just basis for policy and law is to maximize utility.

15:40.000 --> 15:44.540
How many disagree with the utilitarian approach to law

15:46.479 --> 15:48.179
and to the common good?

15:48.640 --> 15:50.060
How many agree with it?

15:52.240 --> 15:53.980
So more agree than disagree.

15:55.319 --> 15:59.039
So let's hear from the critics. Yes?

15:59.719 --> 16:03.219
My main issue with it is that I feel like you can't say

16:03.560 --> 16:07.380
that just because someone's in the minority, what they want

16:07.479 --> 16:10.379
and need is less valuable than someone who is in the majority.

16:11.880 --> 16:14.780
So I guess I have an issue with the idea that the greatest good

16:15.040 --> 16:18.420
for the greatest number is okay because there are still -

16:18.760 --> 16:21.380
what about people who are in the lesser number?

16:21.599 --> 16:22.579
Like, it's not fair to them.

16:22.959 --> 16:25.019
They didn't have any say in where they wanted to be.

16:26.020 --> 16:27.260
All right. That's an interesting objection.

16:27.520 --> 16:29.980
You're worried about the effect on the minority.

16:30.439 --> 16:31.859
Yes.

16:32.640 --> 16:33.420
What's your name, by the way?

16:33.640 --> 16:34.460
Anna.

16:35.040 --> 16:39.340
Who has an answer to Anna's worry about the effect on the minority?

16:39.920 --> 16:41.180
What do you say to Anna?

16:41.359 --> 16:43.739
Um, she said that the minority is valued less.

16:44.240 --> 16:46.380
I don't think that's the case because individually,

16:46.640 --> 16:50.100
the minority's value is just the same as the individual of the majority.

16:50.520 --> 16:54.500
It's just that the numbers outweigh the minority.

16:55.560 --> 16:57.980
And I mean, at a certain point, you have to make a decision

16:58.199 --> 17:01.379
and I'm sorry for the minority but sometimes,

17:01.760 --> 17:04.260
it's for the general, for the greater good.

17:04.720 --> 17:06.420
For the greater good. Anna, what do you say?

17:06.680 --> 17:07.580
What's your name?

17:07.760 --> 17:08.990
Yang-Da.

17:09.090 --> 17:10.460
What do you say to Yang-Da?

17:11.040 --> 17:13.220
Yang-Da says you just have to add up people's preferences

17:13.440 --> 17:16.020
and those in the minority do have their preferences weighed.

17:16.399 --> 17:19.379
Can you give an example of the kind of thing

17:19.639 --> 17:22.899
you're worried about when you say you're worried about utilitarianism

17:23.080 --> 17:26.940
violating the concern or respect due the minority?

17:28.159 --> 17:29.179
And give an example.

17:29.879 --> 17:31.819
Okay. So, well, with any of the cases that we've talked about,

17:32.040 --> 17:37.100
like for the shipwreck one, I think the boy who was eaten

17:37.360 --> 17:41.500
still had as much of a right to live as the other people

17:41.960 --> 17:48.780
and just because he was the minority in that case,

17:49.399 --> 17:52.659
the one who maybe had less of a chance to keep living,

17:53.740 --> 17:56.590
that doesn't mean that the others automatically

17:56.690 --> 18:00.400
have a right to eat him just because it would give a

18:00.500 --> 18:02.460
greater amount of people a chance to live.

18:03.610 --> 18:08.160
So there may be certain rights that the minority members have,

18:08.360 --> 18:14.260
that the individual has that shouldn't be traded off for the sake of utility?

18:14.899 --> 18:16.239
Yes.

18:16.360 --> 18:19.500
Yes, Anna? You know, this would be a test for you.

18:20.149 --> 18:26.419
Back in Ancient Rome, they threw Christians to the lions

18:26.520 --> 18:28.700
in the Colosseum for sport.

18:29.679 --> 18:32.579
If you think how the utilitarian calculus would go,

18:33.000 --> 18:38.020
yes, the Christian thrown to the lions suffers enormous excruciating pain.

18:38.899 --> 18:41.409
But look at the collective ecstasy of the Romans!

18:45.360 --> 18:46.140
Yang-Da.

18:46.760 --> 18:55.780
Well, in that time, I don't -- if -- in modern day of time,

18:56.560 --> 18:59.380
to value the -- to give a number to the happiness

18:59.480 --> 19:04.460
given to the people watching, I don't think any, like,

19:04.800 --> 19:09.580
policymaker would say the pain of one person, of the suffering

19:09.800 --> 19:12.540
of one person is much, much -- is, I mean, in comparison

19:12.919 --> 19:14.339
to the happiness gained, it's -

19:14.800 --> 19:17.340
No, but you have to admit that if there were enough Romans

19:17.560 --> 19:21.740
delirious enough with happiness, it would outweigh even the

19:21.919 --> 19:26.059
most excruciating pain of a handful of Christians thrown to the lion.

19:28.639 --> 19:32.419
So we really have here two different objections to utilitarianism.

19:33.320 --> 19:38.300
One has to do with whether utilitarianism adequately respects

19:38.560 --> 19:43.780
individual rights or minority rights, and the other has to do with

19:44.639 --> 19:52.139
the whole idea of aggregating utility or preferences or values.

19:53.240 --> 19:58.980
Is it possible to aggregate all values to translate them into dollar terms?

20:00.480 --> 20:09.620
There was, in the 1930s, a psychologist who tried

20:10.879 --> 20:13.379
to address this second question.

20:13.760 --> 20:17.500
He tried to prove what utilitarianism assumes,

20:18.560 --> 20:24.460
that it is possible to translate all goods, all values,

20:25.040 --> 20:28.100
all human concerns into a single uniform measure,

20:29.120 --> 20:34.100
and he did this by conducting a survey of young recipients of relief,

20:34.720 --> 20:38.540
this was in the 1930s, and he asked them,

20:38.760 --> 20:42.700
he gave them a list of unpleasant experiences and he asked them,

20:42.840 --> 20:46.700
"How much would you have to be paid to undergo the following experiences?"

20:47.320 --> 20:49.050
and he kept track.

20:50.169 --> 20:52.469
For example, how much would you have to be paid

20:52.570 --> 20:54.480
to have one upper front tooth pulled out?

20:57.530 --> 21:01.970
Or how much would you have to be paid to have one little toe cut off?

21:05.159 --> 21:08.459
Or to eat a live earthworm six inches long?

21:11.090 --> 21:14.670
Or to live the rest of your life on a farm in Kansas?

21:19.870 --> 21:22.510
Or to choke a stray cat to death with your bare hands?

21:24.679 --> 21:31.299
Now, what do you suppose was the most expensive item on that list? - Kansas!

21:32.679 --> 21:33.939
Kansas?

21:37.520 --> 21:40.880
You're right, it was Kansas.

21:43.679 --> 21:47.339
For Kansas, people said they'd have to pay them -

21:47.919 --> 21:50.219
they have to be paid $300,000.

21:57.770 --> 22:01.670
What do you think was the next most expensive?

22:03.159 --> 22:03.939
Not the cat.

22:06.419 --> 22:06.979
Not the tooth.

22:08.399 --> 22:09.139
Not the toe.

22:11.480 --> 22:12.020
The worm!

22:16.760 --> 22:21.310
People said you'd have to pay them $100,000 to eat the worm.

22:23.600 --> 22:25.960
What do you think was the least expensive item?

22:28.050 --> 22:29.140
Not the cat.

22:30.240 --> 22:31.380
The tooth.

22:31.760 --> 22:33.340
During the Depression, people were willing to have their

22:33.560 --> 22:36.940
tooth pulled for only $4,500.

22:37.760 --> 22:39.380
What?

22:40.000 --> 22:45.920
Now, here's what Thorndike concluded from his study.

22:48.159 --> 22:52.179
Any want or a satisfaction which exists exists in some amount

22:52.399 --> 22:54.739
and is therefore measurable.

22:54.960 --> 23:00.240
The life of a dog or a cat or a chicken consists of appetites,

23:00.480 --> 23:03.020
cravings, desires, and their gratifications.

23:04.080 --> 23:07.580
So does the life of human beings, though the appetites

23:07.919 --> 23:10.949
and desires are more complicated.

23:11.960 --> 23:14.940
But what about Thorndike's study?

23:16.040 --> 23:22.180
Does it support Bentham's idea that all goods,

23:22.520 --> 23:27.300
all values can be captured according to a single uniform measure of value?

23:28.360 --> 23:31.950
Or does the preposterous character of those different items on the list

23:32.990 --> 23:37.580
suggest the opposite conclusion that maybe,

23:38.200 --> 23:42.540
whether we're talking about life or Kansas or the worm,

23:44.080 --> 23:50.160
maybe the things we value and cherish can't be captured

23:51.120 --> 23:53.380
according to a single uniform measure of value?

23:54.399 --> 23:57.019
And if they can't, what are the consequences

23:57.879 --> 24:01.379
for the utilitarian theory of morality?

24:02.200 --> 24:04.500
That's a question we'll continue with next time.

24:46.159 --> 24:53.659
Last time, we began to consider some objections to

24:53.879 --> 24:57.859
Jeremy Bentham's version of utilitarianism.

25:02.030 --> 25:08.370
People raised two objections in the discussion we had.

25:08.679 --> 25:13.739
The first was the objection, the claim that utilitarianism,

25:15.050 --> 25:18.950
by concerning itself with the greatest good for the greatest number,

25:19.960 --> 25:24.090
fails adequately to respect individual rights.

25:25.679 --> 25:30.859
Today, we have debates about torture and terrorism.

25:33.480 --> 25:38.670
Suppose a suspected terrorist was apprehended on September 10th

25:41.560 --> 25:48.020
and you had reason to believe that the suspect had crucial information

25:48.240 --> 25:51.260
about an impending terrorist attack that would kill over 3,000 people

25:52.379 --> 25:53.819
and you couldn't extract the information.

25:55.669 --> 26:01.939
Would it be just to torture the suspect to get the information

26:03.169 --> 26:09.859
or do you say no, there is a categorical moral duty

26:10.510 --> 26:12.680
of respect for individual rights?

26:14.949 --> 26:17.749
In a way, we're back to the questions we started with

26:18.110 --> 26:19.920
about Charlie Carson organ transplant.

26:20.149 --> 26:21.929
So that's the first issue.

26:24.139 --> 26:26.549
And you remember, we considered some examples

26:26.879 --> 26:30.809
of cost-benefit analysis, but a lot of people were unhappy

26:31.040 --> 26:34.940
with cost-benefit analysis when it came to placing

26:35.080 --> 26:37.100
a dollar value on human life.

26:40.120 --> 26:43.350
And so that led us to the second objection.

26:44.720 --> 26:48.820
It questioned whether it's possible to translate all values into

26:49.040 --> 26:51.810
a single uniform measure of value.

26:53.060 --> 26:56.420
It asks, in other words, whether all values are commensurable.

26:57.720 --> 27:02.260
Let me give you one other example of an experience.

27:02.620 --> 27:04.430
This actually is a true story.

27:04.530 --> 27:08.500
It comes from personal experience that raises a question

27:08.720 --> 27:12.900
at least about whether all values can be translated without loss

27:14.000 --> 27:16.500
into utilitarian terms.

27:20.199 --> 27:23.629
Some years ago, when I was a graduate student,

27:23.800 --> 27:28.360
I was at Oxford in England and they had men's and women's colleges.

27:28.720 --> 27:30.580
They weren't yet mixed and the women's colleges

27:31.080 --> 27:34.340
had rules against overnight male guests.

27:37.720 --> 27:42.620
By the 1970s, these rules were rarely enforced and easily violated,

27:42.779 --> 27:45.799
or so I was told.

27:50.689 --> 27:53.909
By the late 1970s, when I was there,

27:54.080 --> 27:58.110
pressure grew to relax these rules and it became the subject of debate

27:58.210 --> 28:01.220
among the faculty at St. Anne's College,

28:01.419 --> 28:03.459
which was one of these all-women's colleges.

28:03.840 --> 28:07.880
The older women on the faculty were traditionalists.

28:07.980 --> 28:11.720
They were opposed to change unconventional moral grounds.

28:13.070 --> 28:15.900
But times have changed and they were embarrassed

28:16.159 --> 28:21.019
to give the true grounds for their objection and so they translated

28:21.250 --> 28:24.180
their arguments into utilitarian terms.

28:25.980 --> 28:27.820
"If men stay overnight", they argued,

28:28.490 --> 28:30.270
"the costs to the college will increase."

28:31.750 --> 28:32.900
"How?" you might wonder.

28:33.840 --> 28:35.310
"Well, they'll want to take baths

28:35.570 --> 28:37.170
and that'll use up hot water," they said.

28:39.220 --> 28:40.460
Furthermore, they argued,

28:40.800 --> 28:43.410
"We'll have to replace the mattresses more often."

28:46.020 --> 28:51.170
The reformers met these arguments by adopting the following compromise.

28:52.199 --> 28:57.069
Each woman could have a maximum of three overnight male guests each week.

29:01.320 --> 29:03.860
They didn't say whether it had to be the same one or three different

29:04.800 --> 29:07.900
provided, and this was the compromise,

29:08.159 --> 29:13.539
provided the guest paid 50 pence to defray the cost to the college.

29:15.520 --> 29:20.220
The next day, the national headline in the national newspaper read,

29:20.760 --> 29:22.740
"St. Anne's Girls, 50 Pence A Night."

29:29.320 --> 29:35.220
Another illustration of the difficulty of translating all values,

29:36.280 --> 29:40.580
in this case, a certain idea of virtue, into utilitarian terms.

29:42.439 --> 29:49.859
So, that's all to illustrate the second objection to utilitarianism,

29:50.429 --> 29:55.859
at least the part of that objection, that questions whether utilitarianism

29:56.080 --> 30:02.380
is right to assume that we can assume the uniformity of value,

30:02.959 --> 30:06.779
the commensurability of all values and translate all moral considerations

30:08.120 --> 30:10.940
into dollars or money.

30:12.360 --> 30:15.540
But there is a second aspect to this worry about

30:15.760 --> 30:18.020
aggregating values and preferences.

30:19.679 --> 30:28.019
Why should we weigh all preferences that people have without assessing

30:28.760 --> 30:31.180
whether they're good preferences or bad preferences?

30:32.520 --> 30:38.980
Shouldn't we distinguish between higher pleasures and lower pleasures?

30:40.199 --> 30:46.059
Now, part of the appeal of not making any qualitative distinctions

30:46.639 --> 30:48.419
about the worth of people's preferences,

30:48.679 --> 30:54.139
part of the appeal is that it is nonjudgmental and egalitarian.

30:55.399 --> 30:59.259
The Benthamite utilitarian says everybody's preferences count

31:00.000 --> 31:03.700
and they count regardless of what people want,

31:04.679 --> 31:07.539
regardless of what makes different people happy.

31:08.320 --> 31:11.540
For Bentham, all that matters, you'll remember,

31:13.120 --> 31:17.300
are the intensity and the duration of a pleasure or pain.

31:18.439 --> 31:21.099
The so-called "higher pleasures or nobler virtues"

31:21.679 --> 31:23.459
are simply those, according to Bentham,

31:24.199 --> 31:27.699
that produce stronger, longer pleasure.

31:29.520 --> 31:31.900
Yet a famous phrase to express this idea,

31:33.000 --> 31:38.020
the quantity of pleasure being equal, pushpin is as good as poetry.

31:39.679 --> 31:40.899
What was pushpin?

31:41.679 --> 31:43.619
It was some kind of a child's game, like tiddlywinks.

31:44.240 --> 31:47.220
"Pushpin is as good as poetry", Bentham says.

31:48.879 --> 31:53.099
And lying behind this idea, I think, is the claim, the intuition,

31:53.840 --> 31:58.260
that it's a presumption to judge whose pleasures

31:59.080 --> 32:02.170
are intrinsically higher or worthier or better.

32:04.080 --> 32:07.300
And there is something attractive in this refusal to judge.

32:08.159 --> 32:11.699
After all, some people like Mozart, others Madonna.

32:12.830 --> 32:16.700
Some people like ballet, others bowling.

32:17.439 --> 32:19.739
Who's to say, a Benthamite might argue,

32:20.320 --> 32:24.620
who is to say which of these pleasures, whose pleasures are higher,

32:25.000 --> 32:28.380
worthier, nobler than others?

32:30.679 --> 32:38.419
But is that right, this refusal to make qualitative distinctions?

32:40.439 --> 32:44.659
Can we altogether dispense with the idea that

32:45.360 --> 32:50.980
certain things we take pleasure in are better or worthier than others?

32:52.110 --> 32:55.700
Think back to the case of the Romans in the Colosseum.

32:56.360 --> 32:59.460
One thing that troubled people about that practice is that it seemed

32:59.719 --> 33:02.379
to violate the rights of the Christian.

33:04.320 --> 33:06.460
Another way of objection to what's going on there

33:07.320 --> 33:11.860
is that the pleasure that the Romans take in this bloody spectacle,

33:13.480 --> 33:19.980
should that pleasure, which is abased, kind of corrupt, degrading pleasure,

33:20.480 --> 33:24.980
should that even be valorized or weighed in deciding

33:25.320 --> 33:28.950
what the general welfare is?

33:33.959 --> 33:37.019
So here are the objections to Bentham's utilitarianism

33:38.719 --> 33:43.579
and now, we turn to someone who tried to respond to those objections,

33:45.679 --> 33:48.659
a latter-day utilitarian, John Stuart Mill.

33:50.280 --> 33:56.010
So what we need to examine now is whether John Stuart Mill

33:56.120 --> 34:01.210
had a convincing reply to these objections to utilitarianism.

34:05.040 --> 34:08.340
John Stuart Mill was born in 1806.

34:08.839 --> 34:12.859
His father, James Mill, was a disciple of Bentham's,

34:14.319 --> 34:18.219
and James Mill set about giving his son, John Stuart Mill,

34:18.610 --> 34:20.180
a model education.

34:23.839 --> 34:27.489
He knew Greek at the age of three, Latin at eight,

34:28.110 --> 34:31.220
and age 10, he wrote "A History of Roman Law."

34:33.990 --> 34:38.260
At age 20, he had a nervous breakdown.

34:39.480 --> 34:44.580
This left him in a depression for five years, but at age 25,

34:44.799 --> 34:46.589
what helped lift him out of this depression

34:47.000 --> 34:48.580
is that he met Harriet Taylor.

34:50.110 --> 34:51.900
She and Mill got married, they lived happily ever after,

34:52.640 --> 34:57.380
and it was under her influence that John Stuart Mill

34:57.680 --> 35:00.420
tried to humanize utilitarianism.

35:01.799 --> 35:05.179
What Mill tried to do was to see whether the

35:05.400 --> 35:11.180
utilitarian calculus could be enlarged and modified to

35:11.400 --> 35:18.100
accommodate humanitarian concerns, like the concern to

35:18.279 --> 35:21.899
respect individual rights, and also to address the distinction

35:22.080 --> 35:25.220
between higher and lower pleasures.

35:26.360 --> 35:29.500
In 1859, Mill wrote a famous book on liberty,

35:30.520 --> 35:32.660
the main point of which was the importance

35:32.880 --> 35:35.460
of defending individual rights and minority rights,

35:36.360 --> 35:39.100
and in 1861, toward the end of his life,

35:40.319 --> 35:44.179
he wrote the book we read as part of this course, "Utilitarianism."

35:45.440 --> 35:48.460
He makes it clear that utility is the only standard of morality,

35:49.880 --> 35:53.260
in his view, so he's not challenging Bentham's premise.

35:54.270 --> 35:55.140
He's affirming it.

35:55.680 --> 35:59.140
He says very explicitly, "The sole evidence it is possible

35:59.880 --> 36:05.000
to produce that anything is desirable is that people actually do desire it."

36:06.000 --> 36:10.700
So he stays with the idea that our de facto actual empirical desires

36:10.799 --> 36:13.779
are the only basis for moral judgment.

36:15.870 --> 36:19.980
But then, page eight, also in chapter two,

36:20.360 --> 36:23.730
he argues that it is possible for a utilitarian to distinguish

36:24.830 --> 36:26.530
higher from lower pleasures.

36:28.069 --> 36:31.099
Now, for those of you who have read Mill already,

36:32.480 --> 36:35.910
how, according to him, is it possible to draw that distinction?

36:37.000 --> 36:41.990
How can a utilitarian distinguish qualitatively higher pleasures

36:42.520 --> 36:48.080
from lesser ones, base ones, unworthy ones? Yes?

36:49.040 --> 36:52.450
If you've tried both of them and you prefer the higher one,

36:52.600 --> 36:54.170
naturally, always.

36:55.390 --> 36:56.800
That's great. That's right.

36:57.160 --> 36:57.980
What's your name? - John.

36:58.560 --> 37:03.060
So as John points out, Mill says here's the test.

37:05.080 --> 37:08.180
Since we can't step outside actual desires,

37:08.960 --> 37:13.400
actual preferences that would violate utilitarian premises,

37:13.799 --> 37:20.059
the only test of whether a pleasure is higher or lower

37:20.759 --> 37:26.859
is whether someone who has experienced both would prefer it.

37:27.960 --> 37:33.040
And here, in chapter two, we see the passage where

37:33.140 --> 37:35.500
Mill makes the point that John just described.

37:37.600 --> 37:39.100
"Of two pleasures, if there be one to which

37:39.359 --> 37:44.619
all or almost all who have experience of both give a decided preference,

37:45.779 --> 37:49.099
irrespective of any feeling of moral obligation to prefer it --

37:49.279 --> 37:53.419
in other words, no outside, no independent standard -- then,

37:53.960 --> 37:56.390
that is the more desirable pleasure."

37:56.759 --> 37:59.419
What do people think about that argument?

37:59.940 --> 38:02.660
Does it succeed?

38:03.890 --> 38:07.000
How many think that it does succeed of arguing

38:07.100 --> 38:09.770
within utilitarian terms for a distinction between

38:09.870 --> 38:11.180
higher and lower pleasures?

38:11.680 --> 38:13.400
How many think it doesn't succeed?

38:17.920 --> 38:19.660
I want to hear your reasons.

38:20.960 --> 38:23.260
But before we give the reasons

38:24.040 --> 38:28.740
let's do an experiment of Mill's claim.

38:31.720 --> 38:36.500
In order to do this experiment, we're going to look at

38:36.759 --> 38:42.739
three short excerpts of popular entertainment.

38:45.290 --> 38:47.690
The first one is a Hamlet soliloquy.

38:48.580 --> 38:53.300
It'll be followed by two other experiences.

38:55.520 --> 38:56.540
See what you think.

38:57.640 --> 39:02.900
What a piece of work is a man! How noble in reason!

39:04.880 --> 39:08.260
How infinite in faculties,In form and moving

39:08.560 --> 39:12.300
how express and admirable, in action how like an angel,

39:12.560 --> 39:15.180
in apprehension how like a god!

39:15.400 --> 39:17.700
The beauty of the world, the paragon of animals -

39:18.400 --> 39:22.900
and yet, to me, what is this quintessence of dust?

39:24.680 --> 39:26.020
Man delights not me.（no, nor woman neither. ）

39:42.279 --> 39:45.179
Imagine a world where your greatest fears become reality.

39:45.839 --> 39:47.259
Ahh! They're biting me!

39:47.640 --> 39:49.340
Each show, six contestants from around the country

39:49.640 --> 39:51.620
battle each other in three extreme stunts.

39:51.880 --> 39:52.860
Ow!

39:53.040 --> 39:54.500
These stunts are designed to challenge the contestants

39:54.759 --> 39:58.179
both physically and mentally.

39:59.160 --> 40:02.220
Six contestants, three stunts, one winner.

40:02.440 --> 40:03.940
Yes! Whooo!

40:04.120 --> 40:05.300
Fear Factor.

40:16.160 --> 40:18.180
Hi-diddily-ho, pedal-to-the-metal-o-philes.

40:18.400 --> 40:20.700
Flanders, since when do you like anything cool?

40:21.040 --> 40:23.580
Well, I don't care for the speed but I can't get enough

40:23.680 --> 40:26.580
of that safety gear. Helmets, roll bars, caution flags...

40:27.200 --> 40:28.340
I like the fresh air...

40:28.640 --> 40:30.620
and looking at the poor people in the infield.

40:34.799 --> 40:37.139
Dang, Cletus, why'd you have to park by my parents?

40:37.720 --> 40:40.020
Now, Honey, they's my parents too.

40:55.920 --> 40:58.340
I don't even have to ask which one you liked most.

41:00.759 --> 41:03.139
The Simpsons, how many liked The Simpsons most?

41:05.279 --> 41:06.419
How many Shakespeare?

41:10.240 --> 41:11.660
What about Fear Factor?

41:12.359 --> 41:14.179
How many preferred Fear Factor?

41:16.000 --> 41:17.480
Really?

41:21.580 --> 41:29.180
People overwhelmingly like The Simpsons better than Shakespeare.

41:29.560 --> 41:33.060
All right, now, let's take the other part of the poll,

41:33.880 --> 41:38.540
which is the highest experience or pleasure.

41:39.520 --> 41:42.800
How many say Shakespeare?

41:47.880 --> 41:50.780
How many say Fear Factor?

41:54.359 --> 41:59.339
No, you can't be serious. Really? What?

42:01.200 --> 42:02.180
All right, go ahead. You can say it.

42:03.040 --> 42:04.300
I found that one the most entertaining.

42:05.040 --> 42:07.260
I know, but which do you think was the worthiest,

42:07.480 --> 42:08.860
the noblest experience?

42:09.040 --> 42:10.420
I know you found it the most entertaining.

42:11.000 --> 42:13.830
If something is good just because it is pleasurable,

42:13.930 --> 42:15.380
what does it matter whether you have sort of an

42:15.600 --> 42:20.470
abstract idea of whether it is good by someone else's sense or not?

42:21.040 --> 42:23.620
All right, so you come down in the straight Benthamite side.

42:24.560 --> 42:27.500
Who is to judge and why should we judge,

42:29.160 --> 42:32.620
apart from just registering and aggregating de facto preference?

42:32.799 --> 42:34.259
All right, that's fair enough. And what's your name?

42:35.509 --> 42:36.719
Nate, okay, fair enough.

42:37.400 --> 42:40.080
All right, so how many think The Simpsons is actually,

42:41.180 --> 42:44.060
apart from liking it, is actually the higher experience?

42:46.270 --> 42:47.480
Higher than Shakespeare?

42:47.859 --> 42:49.249
All right, let's see the vote for Shakespeare again.

42:49.799 --> 42:51.139
How many think Shakespeare is higher?

42:52.220 --> 42:55.700
All right. So why is it -- ideally,

42:55.799 --> 42:59.039
I'd like to hear from someone, is there someone who thinks

42:59.240 --> 43:04.420
Shakespeare is highest but who preferred watching The Simpsons?

43:06.799 --> 43:07.899
Yes?

43:08.640 --> 43:10.100
Like, I guess just sitting and watching The Simpsons,

43:10.319 --> 43:12.459
it's entertaining because they make jokes and they make us laugh.

43:12.560 --> 43:16.100
But like, someone has to tell us that Shakespeare was this great writer.

43:16.359 --> 43:18.459
We had to be taught how to read him, how to understand him.

43:18.680 --> 43:21.700
We had to be taught how to kind of take in Rembrandt,

43:21.799 --> 43:22.939
how to analyze a painting.

43:23.470 --> 43:24.220
But let me -- what's your name?

43:24.440 --> 43:25.340
Anisha.

43:25.880 --> 43:29.180
Anisha, when you say someone told you that Shakespeare is better --

43:29.400 --> 43:30.420
Right.

43:30.759 --> 43:33.059
Are you accepting it on blind faith?

43:33.240 --> 43:34.700
You voted that Shakespeare is higher

43:34.920 --> 43:37.540
only because the culture tells you that

43:37.759 --> 43:43.099
or teachers tell you that or do you actually agree with that yourself?

43:43.560 --> 43:46.360
Well, in the sense that Shakespeare no,

43:46.640 --> 43:49.320
but earlier you made an example of Rembrandt.

43:50.160 --> 43:51.900
I feel like I would enjoy reading a comic book

43:52.200 --> 43:54.580
more than I would enjoy kind of analyzing Rembrandt

43:54.799 --> 43:57.019
because someone told me it was great, you know. - Right.

43:57.529 --> 44:00.339
So some of this seems to be, you're suggesting,

44:01.660 --> 44:03.420
a kind of a cultural convention and pressure.

44:03.680 --> 44:07.340
We're told what books, what works of art are great. - Right.

44:08.640 --> 44:09.660
Who else?

44:12.600 --> 44:13.700
Yes?

44:15.240 --> 44:17.140
Although I enjoyed watching The Simpsons more

44:17.359 --> 44:20.679
in this particular moment, in justice, if I were to spend

44:20.779 --> 44:26.259
the rest of my life considering the three different video clips shown,

44:26.799 --> 44:30.099
I would not want to spend that remainder of my life

44:30.319 --> 44:33.459
considering the latter two clips.

44:34.040 --> 44:38.740
I think I would derive more pleasure from being able to branch out in my

44:38.960 --> 44:43.500
own mind sort of considering more deep pleasures, more deep thoughts.

44:44.400 --> 44:45.780
And tell me your name.

44:46.120 --> 44:47.140
Joe.

44:47.319 --> 44:52.459
Joe, so if you had to spend the rest of your life on a farm

44:52.680 --> 44:58.820
in Kansas with only Shakespeare or the collected episodes

44:59.279 --> 45:04.459
of The Simpsons, you would prefer Shakespeare?

45:04.680 --> 45:12.580
What do you conclude from that about John Stuart Mill's test that the test

45:12.799 --> 45:19.739
of a higher pleasure is whether people who have experienced both prefer it?

45:20.879 --> 45:22.739
Can I cite another example briefly?

45:22.960 --> 45:23.700
Yeah.

45:24.040 --> 45:27.020
In Neurobiology last year, we were told of a rat

45:27.240 --> 45:32.140
who was tested a particular center in the brain where the rat was able

45:32.359 --> 45:35.259
to stimulate his brain and caused itself intense pleasure repeatedly.

45:35.960 --> 45:37.980
The rat did not eat or drink until it died.

45:38.319 --> 45:41.219
So the rat was clearly experiencing intense pleasure.

45:42.240 --> 45:43.980
Now, if you ask me right now if I would rather experience

45:44.080 --> 45:48.900
intense pleasure or have a full lifetime of higher pleasure,

45:49.910 --> 45:51.900
I would consider intense pleasure to be low pleasure.

45:52.240 --> 45:54.940
I would right now enjoy intense pleasure but

45:55.720 --> 45:56.780
-- yes, I would.

45:57.480 --> 45:59.540
I certainly would.

46:01.200 --> 46:04.400
But over a lifetime, I think I would think almost a complete majority here would agree that they would rather

46:04.480 --> 46:07.640
a complete majority here would agree that they would rather

46:07.799 --> 46:12.399
be a human with higher pleasure than be that rat with intense pleasure

46:12.850 --> 46:14.620
for a momentary period of time.

46:15.240 --> 46:19.380
Now, in answer to your question, I think this proves that -

46:20.000 --> 46:21.160
or I won't say "proves."

46:21.759 --> 46:26.779
I think the conclusion is that Mill's theory that when a majority

46:27.160 --> 46:29.420
of people are asked what they would rather do,

46:29.640 --> 46:35.700
they will answer that they would rather engage in a higher pleasure.

46:36.400 --> 46:39.300
So you think that this support Mill's you think Mill is onto something here?

46:39.560 --> 46:40.960
I do.

46:41.060 --> 46:44.700
All right, Is there anyone who disagrees with Joe and who thinks

46:44.879 --> 46:50.019
that our experiment disproves Mill's test,

46:51.000 --> 46:54.260
shows that that's not an adequate way, that you can't distinguish

46:54.359 --> 46:57.539
higher pleasures within the utilitarian framework?

47:01.160 --> 47:02.900
Yes?

47:03.120 --> 47:08.100
If whatever is good is truly just whatever people prefer,

47:08.319 --> 47:10.659
it's truly relative and there's no objective definition,

47:11.319 --> 47:14.899
then there will be some society where people prefer Simpsons more.

47:15.640 --> 47:19.780
Anyone can appreciate The Simpsons but I think it does take education

47:20.000 --> 47:21.260
to appreciate Shakespeare as much.

47:21.680 --> 47:23.140
All right, you're saying it takes education

47:23.240 --> 47:25.980
to appreciate higher true things.

47:27.359 --> 47:31.699
Mill's point is that the higher pleasures do require

47:32.520 --> 47:34.780
cultivation and appreciation and education.

47:35.120 --> 47:36.940
He doesn't dispute that.

47:37.640 --> 47:44.740
But once having been cultivated and educated, people will see,

47:45.120 --> 47:48.340
not only see the difference between higher and lower pleasures,

47:49.080 --> 47:54.060
but will actually prefer the higher to the lower.

47:55.680 --> 47:58.380
You find this famous passage from John Stuart Mill.

47:58.680 --> 48:04.980
"It is better to be a human being dissatisfied than a pig satisfied;

48:06.080 --> 48:09.340
better to be Socrates dissatisfied than a fool satisfied.

48:10.600 --> 48:14.380
And if the fool, or the pig, are of a different opinion,

48:15.859 --> 48:19.379
it is because they only know their side of the question."

48:20.839 --> 48:23.739
So here, you have an attempt to distinguish

48:24.200 --> 48:27.140
higher from lower pleasures.

48:28.839 --> 48:31.099
So going to an art museum or being a couch potato

48:31.609 --> 48:34.139
and swilling beer, watching television at home.

48:35.080 --> 48:38.820
Sometimes, Mill agrees, we might succumb to the temptation

48:39.400 --> 48:42.820
to do the latter, to be couch potatoes.

48:44.759 --> 48:50.059
But even when we do that out of indolence and sloth,

48:50.839 --> 48:56.059
we know that the pleasure we get gazing at Rembrandts in the museum

48:57.200 --> 49:01.460
is actually higher because we've experienced both,

49:03.420 --> 49:06.330
and it is a higher pleasure gazing at Rembrandts

49:06.960 --> 49:09.580
because it engages our higher human faculties.

49:11.600 --> 49:16.780
What about Mill's attempt to reply to the objection about individual rights?

49:19.040 --> 49:22.420
In a way, he uses the same kind of argument,

49:25.480 --> 49:27.540
and this comes out in chapter five.

49:28.160 --> 49:31.780
He says, "I dispute the pretensions of any theory which sets up

49:31.879 --> 49:36.179
an imaginary standard of justice not grounded on utility."

49:39.879 --> 49:46.619
But still, he considers justice grounded on utility to be what he calls

49:46.839 --> 49:50.539
"the chief part and incomparably, the most sacred

49:50.879 --> 49:53.539
and binding part of all morality."

49:54.640 --> 49:58.420
So justice is higher, individual rights are privileged,

50:00.120 --> 50:04.540
but not for reasons that depart from utilitarian assumptions.

50:04.720 --> 50:08.060
Justice is a name, for certain moral requirements,

50:09.160 --> 50:12.300
which, regarded collectively, stand higher in the scale

50:12.700 --> 50:19.540
of social utility and are, therefore, of more paramount

50:19.720 --> 50:22.620
obligation than any others.

50:23.240 --> 50:25.020
So justice, it is sacred.

50:25.279 --> 50:26.619
It's prior. It's privileged.

50:26.839 --> 50:29.979
It isn't something that can easily be traded off against lesser things.

50:30.879 --> 50:37.139
But the reason is ultimately, Mill claims, a utilitarian reason

50:38.000 --> 50:41.740
once you consider the long-run interests of humankind,

50:43.720 --> 50:46.380
of all of us as progressive beings.

50:47.799 --> 50:49.979
If we do justice and if we respect rights,

50:50.640 --> 50:54.160
society as a whole will be better off in the long run.

50:55.879 --> 51:00.899
Well, is that convincing or is Mill actually, without admitting it,

51:01.520 --> 51:06.900
stepping outside utilitarian considerations in arguing for

51:08.200 --> 51:13.500
qualitatively higher pleasures and for sacred

51:13.720 --> 51:17.660
or especially important individual rights?

51:18.680 --> 51:23.210
We haven't fully answered that question because to answer that question,

51:23.560 --> 51:25.700
in the case of rights and justice,

51:26.399 --> 51:29.299
will require that we explore other ways,

51:30.279 --> 51:34.459
non-utilitarian ways of accounting for the basis

51:34.680 --> 51:39.260
of rights and then asking whether they succeed.

51:40.480 --> 51:45.260
As for Jeremy Bentham, who launched utilitarianism

51:46.279 --> 51:48.899
as a doctrine in moral and legal philosophy,

51:50.120 --> 51:53.200
Bentham died in 1832 at the age of 85.

51:54.000 --> 51:57.620
But if you go to London, you can visit him today literally.

51:58.879 --> 52:03.139
He provided in his will that his body be preserved,

52:03.640 --> 52:06.940
embalmed, and displayed in the University of London,

52:07.560 --> 52:11.860
where he still presides in a glass case with a wax head,

52:12.520 --> 52:14.740
dressed in his actual clothing.

52:15.120 --> 52:17.980
You see, before he died, Bentham addressed himself

52:18.359 --> 52:21.099
to a question consistent with his philosophy.

52:22.000 --> 52:25.980
Of what use could a dead man be to the living?

52:26.720 --> 52:29.740
One use, he said, would be to make one's corpse

52:29.960 --> 52:32.340
available to the study of anatomy.

52:32.899 --> 52:38.759
In the case of great philosophers, however, better yet to preserve

52:38.859 --> 52:43.579
one's physical presence in order to inspire future generations of thinkers.

52:44.879 --> 52:47.179
You want to see what Bentham looks like stuffed?

52:47.720 --> 52:49.700
Here is what he looks like.

52:50.399 --> 52:52.099
There he is.

52:52.359 --> 52:59.179
Now, if you look closely, you will notice that the embalming

52:59.359 --> 53:02.269
of his actual head was not a success,

53:02.629 --> 53:09.019
so they substituted a waxed head and at the bottom, for verisimilitude,

53:09.240 --> 53:14.180
you can actually see his actual head on a plate.

53:16.680 --> 53:18.540
You see it? Right there.

53:21.520 --> 53:24.030
So, what's the moral of the story?

53:26.140 --> 53:29.780
The moral of the story - and by the way,

53:30.160 --> 53:32.130
they bring him out during meetings of the board

53:32.220 --> 53:34.650
at University College London and the minutes record him

53:34.920 --> 53:37.170
as present but not voting.

53:40.799 --> 53:43.459
Here is a philosopher in life and in death

53:45.500 --> 53:49.400
who adhered to the principles of his philosophy.

53:49.960 --> 53:51.800
We'll continue with rights next time.

53:57.620 --> 54:00.380
Don't miss the chance to interact online with other viewers of Justice.

54:00.960 --> 54:02.780
Join the conversation, take a pop quiz,

54:03.279 --> 54:05.499
watch lectures you've missed, and learn a lot more.

54:05.799 --> 54:08.539
It's at justiceharvard.org. It's the right thing to do.

54:09.540 --> 54:13.540
http://forum-network.org xiaolai
